{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "import logging\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-12 06:56:22,431 : INFO : collecting all words and their counts\n",
      "2018-02-12 06:56:22,434 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-02-12 06:56:25,641 : INFO : collected 279184 word types from a corpus of 10292133 raw words and 1030 sentences\n",
      "2018-02-12 06:56:25,642 : INFO : Loading a fresh vocabulary\n",
      "2018-02-12 06:56:26,056 : INFO : min_count=5 retains 63033 unique words (22% of original 279184, drops 216151)\n",
      "2018-02-12 06:56:26,059 : INFO : min_count=5 leaves 9964035 word corpus (96% of original 10292133, drops 328098)\n",
      "2018-02-12 06:56:26,226 : INFO : deleting the raw counts dictionary of 279184 items\n",
      "2018-02-12 06:56:26,270 : INFO : sample=0.001 downsamples 31 most-common words\n",
      "2018-02-12 06:56:26,272 : INFO : downsampling leaves estimated 6920346 word corpus (69.5% of prior 9964035)\n",
      "2018-02-12 06:56:26,273 : INFO : estimated required memory for 63033 words and 200 dimensions: 132369300 bytes\n",
      "2018-02-12 06:56:26,486 : INFO : resetting layer weights\n",
      "2018-02-12 06:56:27,447 : INFO : training model with 3 workers on 63033 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-02-12 06:56:28,459 : INFO : PROGRESS: at 2.23% examples, 746873 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:29,460 : INFO : PROGRESS: at 4.70% examples, 798554 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:30,460 : INFO : PROGRESS: at 7.11% examples, 811941 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:31,459 : INFO : PROGRESS: at 9.50% examples, 814905 words/s, in_qsize 6, out_qsize 1\n",
      "2018-02-12 06:56:32,474 : INFO : PROGRESS: at 11.88% examples, 818029 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:56:33,470 : INFO : PROGRESS: at 14.21% examples, 816816 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:34,473 : INFO : PROGRESS: at 16.60% examples, 816740 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:35,483 : INFO : PROGRESS: at 19.05% examples, 820052 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:36,492 : INFO : PROGRESS: at 21.50% examples, 821636 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:56:37,493 : INFO : PROGRESS: at 23.96% examples, 822850 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:38,499 : INFO : PROGRESS: at 26.23% examples, 819852 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:56:39,505 : INFO : PROGRESS: at 28.68% examples, 821788 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:56:40,510 : INFO : PROGRESS: at 31.09% examples, 822707 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:56:41,516 : INFO : PROGRESS: at 33.40% examples, 821230 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:42,526 : INFO : PROGRESS: at 35.79% examples, 821588 words/s, in_qsize 6, out_qsize 1\n",
      "2018-02-12 06:56:43,529 : INFO : PROGRESS: at 38.21% examples, 821902 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:44,529 : INFO : PROGRESS: at 40.60% examples, 822943 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:45,533 : INFO : PROGRESS: at 43.11% examples, 823328 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:56:46,536 : INFO : PROGRESS: at 45.53% examples, 824524 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:56:47,532 : INFO : PROGRESS: at 47.98% examples, 825553 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:48,542 : INFO : PROGRESS: at 50.37% examples, 825716 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:49,548 : INFO : PROGRESS: at 52.82% examples, 826644 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:56:50,559 : INFO : PROGRESS: at 55.26% examples, 827274 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:56:51,563 : INFO : PROGRESS: at 57.73% examples, 827790 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:56:52,572 : INFO : PROGRESS: at 60.17% examples, 829026 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:53,572 : INFO : PROGRESS: at 62.60% examples, 828373 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:54,575 : INFO : PROGRESS: at 64.97% examples, 827980 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:55,578 : INFO : PROGRESS: at 67.32% examples, 827615 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:56:56,579 : INFO : PROGRESS: at 69.71% examples, 827421 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:57,585 : INFO : PROGRESS: at 72.10% examples, 827605 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:56:58,591 : INFO : PROGRESS: at 74.49% examples, 827430 words/s, in_qsize 6, out_qsize 1\n",
      "2018-02-12 06:56:59,604 : INFO : PROGRESS: at 76.93% examples, 827553 words/s, in_qsize 6, out_qsize 1\n",
      "2018-02-12 06:57:00,607 : INFO : PROGRESS: at 79.36% examples, 828248 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:57:01,615 : INFO : PROGRESS: at 81.86% examples, 828499 words/s, in_qsize 6, out_qsize 1\n",
      "2018-02-12 06:57:02,628 : INFO : PROGRESS: at 84.31% examples, 828737 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:57:03,625 : INFO : PROGRESS: at 86.74% examples, 829055 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:57:04,634 : INFO : PROGRESS: at 89.20% examples, 829637 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-12 06:57:05,640 : INFO : PROGRESS: at 91.63% examples, 830044 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:57:06,644 : INFO : PROGRESS: at 94.08% examples, 830493 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:57:07,647 : INFO : PROGRESS: at 96.52% examples, 830565 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:57:08,664 : INFO : PROGRESS: at 98.97% examples, 830726 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-12 06:57:09,065 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-02-12 06:57:09,073 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-02-12 06:57:09,078 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-02-12 06:57:09,079 : INFO : training on 51460665 raw words (34599504 effective words) took 41.6s, 831159 effective words/s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "sentences = word2vec.Text8Corpus('filpino_mined_corpus.txt')\n",
    "\n",
    "model = word2vec.Word2Vec(sentences, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-12 07:01:30,276 : INFO : saving Word2Vec object under corpus_mined.model, separately None\n",
      "2018-02-12 07:01:30,278 : INFO : not storing attribute syn0norm\n",
      "2018-02-12 07:01:30,279 : INFO : storing np array 'syn0' to corpus_mined.model.wv.syn0.npy\n",
      "2018-02-12 07:01:31,328 : INFO : storing np array 'syn1neg' to corpus_mined.model.syn1neg.npy\n",
      "2018-02-12 07:01:32,308 : INFO : not storing attribute cum_table\n",
      "2018-02-12 07:01:33,084 : INFO : saved corpus_mined.model\n"
     ]
    }
   ],
   "source": [
    "model.save('corpus_mined.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-12 07:04:45,132 : INFO : storing 63033x200 projection weights into corpus_mined.model.bin\n"
     ]
    }
   ],
   "source": [
    "model.wv.save_word2vec_format('corpus_mined.model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
