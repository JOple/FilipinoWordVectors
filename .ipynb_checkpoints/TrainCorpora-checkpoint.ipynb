{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "import logging\n",
    "from gensim.models import word2vec\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Word2Vec Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entire Corpora\n",
    "  word vectors for the entire corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-19 04:46:48,073 : INFO : collecting all words and their counts\n",
      "2018-03-19 04:46:48,331 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-19 04:46:54,895 : INFO : collected 481359 word types from a corpus of 18502430 raw words and 1851 sentences\n",
      "2018-03-19 04:46:54,896 : INFO : Loading a fresh vocabulary\n",
      "2018-03-19 04:46:55,618 : INFO : min_count=5 retains 108813 unique words (22% of original 481359, drops 372546)\n",
      "2018-03-19 04:46:55,619 : INFO : min_count=5 leaves 17925799 word corpus (96% of original 18502430, drops 576631)\n",
      "2018-03-19 04:46:55,991 : INFO : deleting the raw counts dictionary of 481359 items\n",
      "2018-03-19 04:46:56,029 : INFO : sample=0.001 downsamples 31 most-common words\n",
      "2018-03-19 04:46:56,029 : INFO : downsampling leaves estimated 12711961 word corpus (70.9% of prior 17925799)\n",
      "2018-03-19 04:46:56,030 : INFO : estimated required memory for 108813 words and 200 dimensions: 228507300 bytes\n",
      "2018-03-19 04:46:56,571 : INFO : resetting layer weights\n",
      "2018-03-19 04:46:58,139 : INFO : training model with 3 workers on 108813 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-03-19 04:46:59,146 : INFO : PROGRESS: at 1.20% examples, 766359 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:00,157 : INFO : PROGRESS: at 2.56% examples, 799792 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-19 04:47:01,163 : INFO : PROGRESS: at 3.87% examples, 804876 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-19 04:47:02,166 : INFO : PROGRESS: at 5.18% examples, 810886 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-19 04:47:03,174 : INFO : PROGRESS: at 6.48% examples, 812475 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:04,177 : INFO : PROGRESS: at 7.77% examples, 813516 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-19 04:47:05,178 : INFO : PROGRESS: at 9.05% examples, 813433 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-19 04:47:06,188 : INFO : PROGRESS: at 10.34% examples, 813227 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-19 04:47:07,189 : INFO : PROGRESS: at 11.66% examples, 813935 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:08,197 : INFO : PROGRESS: at 12.98% examples, 817132 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-19 04:47:09,200 : INFO : PROGRESS: at 14.14% examples, 815606 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:10,206 : INFO : PROGRESS: at 15.47% examples, 817394 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:11,211 : INFO : PROGRESS: at 16.82% examples, 818669 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-19 04:47:12,214 : INFO : PROGRESS: at 18.11% examples, 818706 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-19 04:47:13,221 : INFO : PROGRESS: at 19.45% examples, 820264 words/s, in_qsize 4, out_qsize 1\n",
      "2018-03-19 04:47:14,227 : INFO : PROGRESS: at 20.77% examples, 820944 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:15,241 : INFO : PROGRESS: at 22.09% examples, 821129 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-19 04:47:16,245 : INFO : PROGRESS: at 23.44% examples, 821228 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-19 04:47:17,252 : INFO : PROGRESS: at 24.73% examples, 821237 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-19 04:47:18,260 : INFO : PROGRESS: at 26.03% examples, 820797 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-19 04:47:19,261 : INFO : PROGRESS: at 27.26% examples, 818964 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-19 04:47:20,265 : INFO : PROGRESS: at 28.50% examples, 817583 words/s, in_qsize 4, out_qsize 1\n",
      "2018-03-19 04:47:21,279 : INFO : PROGRESS: at 29.77% examples, 816330 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-19 04:47:22,284 : INFO : PROGRESS: at 31.10% examples, 816824 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:23,285 : INFO : PROGRESS: at 32.39% examples, 817320 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:24,295 : INFO : PROGRESS: at 33.60% examples, 815656 words/s, in_qsize 5, out_qsize 1\n",
      "2018-03-19 04:47:25,297 : INFO : PROGRESS: at 34.89% examples, 817852 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:26,297 : INFO : PROGRESS: at 36.21% examples, 817685 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:27,298 : INFO : PROGRESS: at 37.51% examples, 818094 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:28,302 : INFO : PROGRESS: at 38.87% examples, 819284 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:29,308 : INFO : PROGRESS: at 40.16% examples, 819005 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:30,316 : INFO : PROGRESS: at 41.52% examples, 820614 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-19 04:47:31,325 : INFO : PROGRESS: at 42.88% examples, 820810 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-19 04:47:32,334 : INFO : PROGRESS: at 44.25% examples, 821662 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:33,334 : INFO : PROGRESS: at 45.58% examples, 822352 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:34,334 : INFO : PROGRESS: at 46.89% examples, 822569 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:35,345 : INFO : PROGRESS: at 48.22% examples, 823068 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:36,351 : INFO : PROGRESS: at 49.55% examples, 823417 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-19 04:47:37,359 : INFO : PROGRESS: at 50.89% examples, 823586 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:38,362 : INFO : PROGRESS: at 52.22% examples, 824233 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-19 04:47:39,371 : INFO : PROGRESS: at 53.48% examples, 823764 words/s, in_qsize 4, out_qsize 1\n",
      "2018-03-19 04:47:40,387 : INFO : PROGRESS: at 54.81% examples, 825427 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:41,396 : INFO : PROGRESS: at 56.19% examples, 825814 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:42,405 : INFO : PROGRESS: at 57.51% examples, 826058 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:43,406 : INFO : PROGRESS: at 58.88% examples, 826875 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:44,421 : INFO : PROGRESS: at 60.14% examples, 825962 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:45,425 : INFO : PROGRESS: at 61.49% examples, 826800 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:46,426 : INFO : PROGRESS: at 62.85% examples, 826988 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:47,427 : INFO : PROGRESS: at 64.18% examples, 827141 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-19 04:47:48,432 : INFO : PROGRESS: at 65.53% examples, 827714 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-19 04:47:49,433 : INFO : PROGRESS: at 66.85% examples, 827757 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:50,449 : INFO : PROGRESS: at 68.19% examples, 828073 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-19 04:47:51,452 : INFO : PROGRESS: at 69.53% examples, 828404 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-19 04:47:52,457 : INFO : PROGRESS: at 70.86% examples, 828355 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-19 04:47:53,458 : INFO : PROGRESS: at 72.17% examples, 828424 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:54,460 : INFO : PROGRESS: at 73.44% examples, 828281 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-19 04:47:55,460 : INFO : PROGRESS: at 74.73% examples, 829222 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:56,461 : INFO : PROGRESS: at 76.07% examples, 829288 words/s, in_qsize 4, out_qsize 1\n",
      "2018-03-19 04:47:57,463 : INFO : PROGRESS: at 77.37% examples, 829198 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:58,467 : INFO : PROGRESS: at 78.71% examples, 829508 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:47:59,471 : INFO : PROGRESS: at 80.01% examples, 829246 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-19 04:48:00,478 : INFO : PROGRESS: at 81.37% examples, 829873 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-19 04:48:01,478 : INFO : PROGRESS: at 82.72% examples, 829845 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:48:02,488 : INFO : PROGRESS: at 84.08% examples, 830149 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:48:03,490 : INFO : PROGRESS: at 85.40% examples, 830258 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:48:04,496 : INFO : PROGRESS: at 86.74% examples, 830421 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:48:05,500 : INFO : PROGRESS: at 88.07% examples, 830638 words/s, in_qsize 6, out_qsize 0\n",
      "2018-03-19 04:48:06,500 : INFO : PROGRESS: at 89.41% examples, 830921 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-19 04:48:07,509 : INFO : PROGRESS: at 90.75% examples, 830920 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-19 04:48:08,511 : INFO : PROGRESS: at 92.08% examples, 831062 words/s, in_qsize 4, out_qsize 0\n",
      "2018-03-19 04:48:09,519 : INFO : PROGRESS: at 93.33% examples, 830620 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:48:10,522 : INFO : PROGRESS: at 94.60% examples, 831161 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:48:11,526 : INFO : PROGRESS: at 95.96% examples, 831330 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:48:12,540 : INFO : PROGRESS: at 97.26% examples, 830974 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:48:13,540 : INFO : PROGRESS: at 98.58% examples, 831163 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:48:14,553 : INFO : PROGRESS: at 99.86% examples, 830712 words/s, in_qsize 5, out_qsize 0\n",
      "2018-03-19 04:48:14,638 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-19 04:48:14,643 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-19 04:48:14,650 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-19 04:48:14,650 : INFO : training on 92512150 raw words (63559796 effective words) took 76.5s, 830763 effective words/s\n"
     ]
    }
   ],
   "source": [
    "sentences = word2vec.Text8Corpus('cleaned/entire_corpora.txt')\n",
    "\n",
    "model = word2vec.Word2Vec(sentences, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-19 04:51:14,209 : INFO : saving Word2Vec object under entire_corpora.model, separately None\n",
      "2018-03-19 04:51:14,210 : INFO : not storing attribute syn0norm\n",
      "2018-03-19 04:51:14,212 : INFO : storing np array 'syn0' to entire_corpora.model.wv.syn0.npy\n",
      "2018-03-19 04:51:15,512 : INFO : not storing attribute cum_table\n",
      "2018-03-19 04:51:15,513 : INFO : storing np array 'syn1neg' to entire_corpora.model.syn1neg.npy\n",
      "2018-03-19 04:51:17,089 : INFO : saved entire_corpora.model\n",
      "2018-03-19 04:51:17,090 : INFO : storing 108813x200 projection weights into entire_corpora.model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save('entire_corpora.model')\n",
    "model.wv.save_word2vec_format('entire_corpora.model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpora Mined \n",
    "    <insert source here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filipiniana\n",
    "    <insert source here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mcfarland\n",
    "    <insert source here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('maam', 0.7244711518287659),\n",
       " ('rama', 0.7057576179504395),\n",
       " ('annabelle', 0.6966278553009033),\n",
       " ('tito', 0.6941772103309631),\n",
       " ('ate', 0.6864875555038452),\n",
       " ('bossing', 0.6799117922782898),\n",
       " ('nora', 0.6723470687866211),\n",
       " ('wilma', 0.6718800067901611),\n",
       " ('lolit', 0.6599768400192261),\n",
       " ('alfie', 0.6526983380317688)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['lalaki', 'tita'], negative=['babae'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
